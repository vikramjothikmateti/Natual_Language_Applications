{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc8270eb",
   "metadata": {},
   "source": [
    "# Methodology of task:\n",
    "\n",
    "1. Text cleaning:\n",
    "The function clean_text cleans each document by:\n",
    "Converting text to lowercase.\n",
    "Removing punctuation and symbols.\n",
    "Removing extra whitespace.\n",
    "The cleaned text is stored in a new column called 'cleaned_document'.\n",
    "\n",
    "2. TF-IDF Vectorization:\n",
    "TfidfVectorizer converts the cleaned text into a matrix of TF-IDF features.\n",
    "TF-IDF measures how important a word is in a document relative to the entire corpus.\n",
    "The shape of the resulting matrix and the size of the vocabulary are printed.\n",
    "\n",
    "3.  Word2Vec Vectorization:\n",
    "The documents are tokenized into individual words using word_tokenize.\n",
    "A Word2Vec model is trained on these tokenized documents:\n",
    "vector_size=100: Each word is represented by a 100-dimensional vector.\n",
    "window=5: Considers a window of 5 words around the target word.\n",
    "min_count=1: Includes words that appear at least once.\n",
    "epochs=100: Trains the model for 100 iterations.\n",
    "sg=1: Uses the Skip-gram model for training.\n",
    "The size of the Word2Vec vectors and the vocabulary are printed.\n",
    "\n",
    "4. Document vector creation:\n",
    "The function document_vector computes the mean of the Word2Vec vectors for all words in a document, creating a single vector to represent the document. If a word is not in the modelâ€™s vocabulary, it is skipped.\n",
    "A list of document vectors is generated for all documents in the dataset.\n",
    "\n",
    "5. Similarity functions:\n",
    "TF-IDF Similarity: The function tf_idf_similarity calculates the cosine similarity between a query (input text) and all documents based on their TF-IDF representations.\n",
    "Word2Vec Similarity: The function word2vec_similarity computes the cosine similarity between a query's vector (computed using Word2Vec) and all document vectors.\n",
    "\n",
    "6. Querying documents:\n",
    "A list of queries is defined, and for each query, the code computes the similarity with all documents using both TF-IDF and Word2Vec models.\n",
    "The function get_top_5_similar retrieves the indices of the top 5 most similar documents.\n",
    "7. Displaying results:\n",
    "The code prints the top 5 most similar documents for each query using both TF-IDF and Word2Vec methods side by side. The document indices are printed (starting from 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c07b78c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in the DataFrame: Index(['documents'], dtype='object')\n",
      "TF-IDF vector size: 328\n",
      "TF-IDF vocabulary size: 328\n",
      "Word2Vec vector size: 100\n",
      "Word2Vec vocabulary size: 329\n",
      "-------- Results for query #1 -----------------\n",
      "TF-IDF\t\tWord2Vec\n",
      "-------------------------------------------------\n",
      "Document 7\tDocument 7\n",
      "Document 9\tDocument 8\n",
      "Document 8\tDocument 9\n",
      "Document 4\tDocument 10\n",
      "Document 5\tDocument 6\n",
      "\n",
      "\n",
      "-------- Results for query #2 -----------------\n",
      "TF-IDF\t\tWord2Vec\n",
      "-------------------------------------------------\n",
      "Document 10\tDocument 10\n",
      "Document 5\tDocument 7\n",
      "Document 1\tDocument 8\n",
      "Document 8\tDocument 5\n",
      "Document 4\tDocument 1\n",
      "\n",
      "\n",
      "-------- Results for query #3 -----------------\n",
      "TF-IDF\t\tWord2Vec\n",
      "-------------------------------------------------\n",
      "Document 10\tDocument 10\n",
      "Document 5\tDocument 5\n",
      "Document 1\tDocument 2\n",
      "Document 4\tDocument 1\n",
      "Document 8\tDocument 6\n",
      "\n",
      "\n",
      "-------- Results for query #4 -----------------\n",
      "TF-IDF\t\tWord2Vec\n",
      "-------------------------------------------------\n",
      "Document 4\tDocument 5\n",
      "Document 10\tDocument 2\n",
      "Document 5\tDocument 4\n",
      "Document 3\tDocument 10\n",
      "Document 1\tDocument 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Reading the input document\n",
    "df = pd.read_csv('assignment3_data.csv')\n",
    "\n",
    "# Check the column names\n",
    "print(\"Column names in the DataFrame:\", df.columns)\n",
    "\n",
    "# Use the first column, regardless of its name\n",
    "document_column = df.columns[0]\n",
    "\n",
    "# Cleaning up the input\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and symbols\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df['cleaned_document'] = df[document_column].apply(clean_text)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['cleaned_document'])\n",
    "\n",
    "print(\"TF-IDF vector size:\", tfidf_matrix.shape[1])\n",
    "print(\"TF-IDF vocabulary size:\", len(tfidf_vectorizer.get_feature_names_out()))\n",
    "\n",
    "\n",
    "# Word2Vec Vectorization\n",
    "tokenized_documents = [word_tokenize(doc) for doc in df['cleaned_document']]\n",
    "\n",
    "# Word2Vec model parameters\n",
    "vector_size = 100\n",
    "window = 5\n",
    "min_count = 1\n",
    "epochs = 100\n",
    "\n",
    "# Training Word2Vec model\n",
    "word2vec_model = Word2Vec(tokenized_documents, vector_size=vector_size, window=window, min_count=min_count, epochs=epochs, sg=1)\n",
    "\n",
    "print(\"Word2Vec vector size:\", word2vec_model.vector_size)\n",
    "print(\"Word2Vec vocabulary size:\", len(word2vec_model.wv.key_to_index))\n",
    "\n",
    "\n",
    "# Function to calculate document vector (mean of word vectors)\n",
    "def document_vector(doc):\n",
    "    words = word_tokenize(doc)\n",
    "    word_vectors = [word2vec_model.wv[word] for word in words if word in word2vec_model.wv]\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(vector_size)\n",
    "\n",
    "# Calculate document vectors for all documents\n",
    "document_vectors = np.array([document_vector(doc) for doc in df['cleaned_document']])\n",
    "\n",
    "# Function to calculate TF-IDF similarity\n",
    "def tf_idf_similarity(query):\n",
    "    query_vector = tfidf_vectorizer.transform([clean_text(query)])\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix).flatten()\n",
    "    return similarities\n",
    "\n",
    "# Function to calculate Word2Vec similarity\n",
    "def word2vec_similarity(query):\n",
    "    query_vector = document_vector(clean_text(query))\n",
    "    similarities = cosine_similarity([query_vector], document_vectors).flatten()\n",
    "    return similarities\n",
    "\n",
    "# Query documents\n",
    "queries = [\n",
    "    \"Artificial intelligence is set to take over most jobs in near future.\",\n",
    "    \"The use of artificial intelligence in healthcare industry is more and more every day.\",\n",
    "    \"The use of AI in healthcare industry is more and more every day.\",\n",
    "    \"The use of AI in medical care is more and more every day\"\n",
    "]\n",
    "\n",
    "# Function to get top 5 similar documents\n",
    "def get_top_5_similar(similarities):\n",
    "    top_5 = np.argsort(similarities)[-5:][::-1] + 1  # Adding 1 to start from 1 instead of 0\n",
    "    return top_5\n",
    "\n",
    "# Iterate over queries and print results\n",
    "for i, query in enumerate(queries, 1):\n",
    "    print(f\"-------- Results for query #{i} -----------------\")\n",
    "    print(\"TF-IDF\\t\\tWord2Vec\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    tfidf_sim = tf_idf_similarity(query)\n",
    "    word2vec_sim = word2vec_similarity(query)\n",
    "    \n",
    "    tfidf_top_5 = get_top_5_similar(tfidf_sim)\n",
    "    word2vec_top_5 = get_top_5_similar(word2vec_sim)\n",
    "    \n",
    "    for j in range(5):\n",
    "        print(f\"Document {tfidf_top_5[j]}\\tDocument {word2vec_top_5[j]}\")\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54eaf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
